{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f556030-1582-4d41-b73c-3c57e0ddff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 08:40:56.677648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751006456.685961   14864 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751006456.688360   14864 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, Softmax, MaxPool2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d23ba46-f578-4621-a16e-058a0943f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data_dir, train=False, batch_size=32, max_files=None, labelMask = False, start_file=None, workers=1, use_multiprocessing=False, sort=True, max_queue_size=10, max_len = 8192, s_freq = 6000, mask_size = 57, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data_dir = data_dir\n",
    "        self.train = train\n",
    "        self.batch_size = batch_size\n",
    "        self.max_files = max_files\n",
    "        self.start_file = start_file\n",
    "        self.sort = sort\n",
    "        self.max_len = max_len\n",
    "        self.s_freq = s_freq\n",
    "        self.mask_size = mask_size\n",
    "        self.labelMask = labelMask\n",
    "\n",
    "        # Load file list\n",
    "        if self.sort:\n",
    "            self.file_list = sorted(os.listdir(data_dir))\n",
    "            if self.max_files:\n",
    "                self.file_list = self.file_list[:self.max_files]\n",
    "            if self.start_file:\n",
    "                self.file_list = self.file_list[self.start_file:]\n",
    "        else:\n",
    "            self.file_list = os.listdir(data_dir)[:self.max_files] if self.max_files else os.listdir(data_dir)\n",
    "\n",
    "        self.workers = workers\n",
    "        self.use_multiprocessing = use_multiprocessing\n",
    "        self.max_queue_size = max_queue_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of batches.\"\"\"\n",
    "        return int(np.ceil(len(self.file_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Load a batch of data.\"\"\"\n",
    "        batch_indices = self.indices[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_files = [self.file_list[i] for i in batch_indices]\n",
    "        batch_X, batch_P, batch_S, batch_N = [], [], [], []\n",
    "\n",
    "        for idx, file_name in enumerate(batch_files):\n",
    "            try:\n",
    "                # Read the txt file\n",
    "                Xnp, p_idx, s_idx = self.readNPZ(file_name)\n",
    "                X, P, S, N,_ = self.preprocess(Xnp, p_idx, s_idx)\n",
    "                \n",
    "                X = np.expand_dims(X, axis=0)\n",
    "                P = np.expand_dims(P, axis=0)\n",
    "                S = np.expand_dims(S, axis=0)\n",
    "                N = np.expand_dims(N, axis=0)\n",
    "                batch_X.append(X)\n",
    "                batch_P.append(P)\n",
    "                batch_S.append(S)\n",
    "                batch_N.append(N)\n",
    "            except Exception as e:\n",
    "                print('Error in processing get_item arrays')\n",
    "                print(e)\n",
    "                continue\n",
    "        try:\n",
    "            batch_X = np.array(batch_X)\n",
    "            batch_P = np.array(batch_P)\n",
    "            batch_S = np.array(batch_S)\n",
    "            batch_N = np.array(batch_N)\n",
    "            batch_label = tf.stack([batch_P, batch_S, batch_N],axis=-1)\n",
    "        except Exception as e:\n",
    "            print('Error in creating arrays')\n",
    "            print(e)\n",
    "        return (batch_X, batch_label)\n",
    "\n",
    "    def preprocess(self, X, p_idx, s_idx, MaxAmpIdx=0):\n",
    "        \"\"\"\n",
    "        Preprocesses the input data to generate P and S arrays.\n",
    "        :param X: Input array.\n",
    "        :param p_idx: Index of the P pick.\n",
    "        :param s_idx: Index of the S pick.\n",
    "        :param MaxAmpIdx: Index of the common time maxAmp if the training set contains it.\n",
    "        :return: Processed X, P, and S arrays.\n",
    "        \"\"\"\n",
    "\n",
    "        # Ensure non-negative P and S\n",
    "        p_idx, s_idx = max(0, p_idx), max(0, s_idx)\n",
    "\n",
    "        # Shift (during training) and pad\n",
    "        X, idx_shift, wind = Pad(X, p_idx, s_idx, self.train)\n",
    "\n",
    "        # Adjust indices based on padding and if it is in the window\n",
    "        p_idx = 0 if wind[0] else p_idx + idx_shift if p_idx else p_idx\n",
    "        s_idx = 0 if wind[1] else s_idx + idx_shift if s_idx else s_idx\n",
    "\n",
    "        # Initialize P and S\n",
    "        P, S, N = np.zeros(self.max_len), np.zeros(self.max_len), np.zeros(self.max_len)\n",
    "\n",
    "        # Fetch the target mask of the subclass\n",
    "        mask = self.targetMask()\n",
    "        \n",
    "        # Fit single arrival mask\n",
    "        \n",
    "        P = self.fitMask(p_idx, mask, P)\n",
    "        S = self.fitMask(s_idx, mask, S)\n",
    "\n",
    "    \n",
    "        ############################################################################################################\n",
    "        # Ensure pdf output\n",
    "        if not self.train:\n",
    "            P /= P.sum() if P.sum() != 0 else 1\n",
    "            S /= S.sum() if S.sum() != 0 else 1\n",
    "        else:\n",
    "            P = P / P.sum() if P.sum() != 0 else softmax(P)\n",
    "            S = S / S.sum() if S.sum() != 0 else softmax(S)\n",
    "\n",
    "        # fig, ax = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "        # ax[0].plot(X)\n",
    "        # ax[1].plot(P,label = \"P label\")\n",
    "        # # ax[1].plot(pSoft, label=\"P label\")\n",
    "        # ax[1].plot(S,label = \"S label\")\n",
    "        # # ax[1].plot(N, label=\"N label\")\n",
    "        # # ax[0].set_title(name)\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "        return X, P, S,N, idx_shift\n",
    "\n",
    "    def fitMask(self, idx, mask, PS_array):\n",
    "        maskLen = len(mask)\n",
    "        if (idx != 0) and (idx < self.max_len):\n",
    "            start = int(np.ceil(idx - maskLen / 2))\n",
    "            end = int(np.ceil(idx + maskLen / 2))\n",
    "            if start >= 0 and end <= len(PS_array):\n",
    "                PS_array[start:end] = np.maximum(PS_array[start:end], mask)\n",
    "            elif np.ceil((maskLen / 2) + len(PS_array)) >= end > len(PS_array):\n",
    "                PS_array[start:] = np.maximum(PS_array[start:],mask[:(len(PS_array) - end)])\n",
    "            elif np.ceil(-(maskLen / 2)) < start < 0:\n",
    "                PS_array[0:end] = np.maximum( PS_array[0:end], mask[np.abs(start):])\n",
    "        return PS_array\n",
    "        \n",
    "    def popMultiMasks(self, Arv, idx_shift, masks, PS_array, X):\n",
    "        for a, arr in enumerate(Arv):\n",
    "            if arr <= 0:\n",
    "                continue\n",
    "            arr += idx_shift\n",
    "            if arr >= 8192 or X[arr][2] == 0:\n",
    "                continue\n",
    "            mask = masks[a]\n",
    "            # print(mask)\n",
    "            # print(len(mask))\n",
    "            idx = arr\n",
    "            PS_array = self.fitMask(idx, mask, PS_array)\n",
    "        return PS_array\n",
    "\n",
    "    def get_single(self,idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        try:\n",
    "            Xnp, p_idx, s_idx, MaxAmpIdx = self.readNPZ(file_name)\n",
    "            X, P, S, N, idx_shift = self.preprocess(Xnp, p_idx, s_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing single file {file_name}: {e}\")\n",
    "        return X, P, S, idx_shift\n",
    "\n",
    "    def total_len(self):\n",
    "        \"\"\"Return the total number of files.\"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.file_list))\n",
    "\n",
    "    def targetMask(self):\n",
    "        if self.labelMask:\n",
    "            return \n",
    "        else:\n",
    "            max_value = 1\n",
    "    \n",
    "            ascending_part = np.linspace(0, max_value, self.mask_size // 2, endpoint=False)\n",
    "            descending_part = np.linspace(max_value, 0, self.mask_size // 2 + 1, endpoint=True)\n",
    "    \n",
    "            pdf = np.concatenate((ascending_part, descending_part))\n",
    "            pdf = pdf / np.sum(pdf)  # Ensures pdf adds up to 1\n",
    "            mask = pdf\n",
    "            return mask\n",
    "        \n",
    "    # Get Labels returns the modes for the P and S waves of the target distribution\n",
    "    def getLabels(self):\n",
    "        labels = []\n",
    "        for file_name in self.file_list:\n",
    "            try:\n",
    "                Xnp, p_idx, s_idx = self.readNPZ(file_name)\n",
    "\n",
    "                # If getLabels is used, make sure to not shuffle and that random is False\n",
    "                _, P, S, _, _ = self.preprocess(Xnp, p_idx, s_idx)\n",
    "\n",
    "                p_idx = P.argmax()\n",
    "                s_idx = S.argmax()\n",
    "\n",
    "                labels.append(np.array([p_idx, s_idx]))\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Error in getting labels')\n",
    "                print(e)\n",
    "\n",
    "        labels = np.vstack([labels])\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def readNPZ(self,fileName):\n",
    "        try:\n",
    "            filePath = os.path.join(dataDir, fileName)\n",
    "            with gzip.open(filePath, 'rt') as file:\n",
    "                ## extract p and s labels\n",
    "                firstLine = file.readline().strip()\n",
    "                ## extract seismogram as colomns of x,y,z\n",
    "                df = pd.read_csv(file,header=None, engine='python')\n",
    "                ## extract information from the dataframe\n",
    "                labels = np.array(firstLine.split(','), dtype=int)\n",
    "        except Exception as e:\n",
    "                print(f\"Error reading file with 'c' and 'python' engines: {e}\")\n",
    "        try:\n",
    "            X = df.iloc[0:, :3]\n",
    "            pIdx = labels[0]\n",
    "            sIdx = labels[1]\n",
    "        except Exception as e:\n",
    "            print('Error in processing arrays')\n",
    "            print(e)\n",
    "            print(file_path)\n",
    "        return X, pIdx, sIdx\n",
    "\n",
    "    def fileDict(self, idx):\n",
    "        dict = np.array(self.file_list)[idx]\n",
    "        return dict\n",
    "\n",
    "    def fileSet(self):\n",
    "        return np.array(self.file_list)\n",
    "\n",
    "    def getFileIndex(self,search_string):\n",
    "        index = next((i for i, s in enumerate(self.file_list) if search_string in s), -1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "245c4402-634e-4442-a112-8cb4ada87b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pad(X, p_idx, s_idx, random=False, maxAmpIdx = 0, max_len=8192):\n",
    "\n",
    "    ### Sub Functions\n",
    "    def standardize(x):  #\n",
    "        maxAbsAmp = np.max(np.abs(x))\n",
    "        if maxAbsAmp != 0:\n",
    "            x /= maxAbsAmp\n",
    "        return x\n",
    "\n",
    "    def make_X(X, random, idx_shift):\n",
    "        if random != True:\n",
    "            idx_shift = 0\n",
    "        x0 = X[:, 0]\n",
    "        x1 = X[:, 1]\n",
    "        x2 = X[:, 2]\n",
    "\n",
    "        x0 = np.pad(x0, (idx_shift, max_len), mode='constant')[:max_len]\n",
    "        x1 = np.pad(x1, (idx_shift, max_len), mode='constant')[:max_len]\n",
    "        x2 = np.pad(x2, (idx_shift, max_len), mode='constant')[:max_len]\n",
    "\n",
    "        X = np.column_stack([x0, x1, x2])\n",
    "\n",
    "        return X, idx_shift\n",
    "\n",
    "    def backpad(X):\n",
    "        # Check if X has the correct number of dimensions\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"Input array X must be a 2D array.\")\n",
    "        zeros_to_add = np.subtract((max_len, 3), X.shape)\n",
    "        rX = np.pad(X, ((0, zeros_to_add[0]), (0, 0)), mode='constant')\n",
    "        return rX\n",
    "\n",
    "    def is_within_slice(idx, slice_obj):\n",
    "        start = slice_obj.start\n",
    "        stop = slice_obj.stop\n",
    "        # Check if value is within the range and aligns with the step\n",
    "        return start <= idx < stop\n",
    "\n",
    "    #####################################################################################\n",
    "    \n",
    "    # Apply standardize function along axis\n",
    "    X = np.apply_along_axis(standardize, axis=0, arr=X)\n",
    "\n",
    "    idx_shift = 0\n",
    "    s_pad = 1500  # number of samples I want to keep after the S pick\n",
    "    p_pad = 2500  # number of samples I want to keep after the P pick (if there is only a P pick)\n",
    "    end_pad = 50  # to be able to put gaussian in without issue\n",
    "    wind = [False, False] # When random == False; Check if the indices lie in the calculated window!\n",
    "\n",
    "    ## No shuffling\n",
    "    if (X.shape[0] < max_len): # Case 1 - 4\n",
    "        idx_shift = 0\n",
    "        X, idx_shift = make_X(X, random, idx_shift)\n",
    "        return X, idx_shift, wind\n",
    "    elif X.shape[0] >= max_len: # i.e. X.shape[0] >= max_len\n",
    "        if maxAmpIdx > 0:\n",
    "            max_val = maxAmpIdx\n",
    "            # print(max_val)\n",
    "        else:\n",
    "            row_norms = np.sqrt(np.sum(X ** 2, axis=1))\n",
    "            max_val = np.argmax(row_norms, axis=0)\n",
    "        # max_val =\n",
    "        # max_index = max_val[2]  # files always have data in third column\n",
    "        max_index = max_val\n",
    "        start_index = max_index - max_len // 2\n",
    "        end_index = max_index + max_len // 2\n",
    "\n",
    "        if (max_index <= max_len) or (max_index <= start_index) or (start_index < 0):\n",
    "            slice_range = slice(0,max_len)\n",
    "            X = X[slice_range, :]\n",
    "            idx_shift = 0\n",
    "            if not is_within_slice(p_idx, slice_range):\n",
    "                wind[0] = True\n",
    "            if not is_within_slice(s_idx, slice_range):\n",
    "                wind[1] = True\n",
    "\n",
    "        elif end_index > X.shape[0]:\n",
    "            slice_range = slice(-max_len,X.shape[0])\n",
    "            X = X[slice_range, :]\n",
    "            idx_shift = max_len - X.shape[0]\n",
    "            if not is_within_slice(p_idx, slice_range):\n",
    "                wind[0] = True\n",
    "            if not is_within_slice(s_idx, slice_range):\n",
    "                wind[1] = True\n",
    "\n",
    "            # if not is_within_slice(p_idx, slice_range) or not is_within_slice(s_idx, slice_range):\n",
    "            #     # print(\"Label not in slice range:\")\n",
    "            #     idx_shift = None\n",
    "\n",
    "        else:\n",
    "            slice_range = slice(start_index, end_index)\n",
    "            X = X[slice_range, :]\n",
    "            idx_shift = max_len - end_index\n",
    "            # if not is_within_slice(p_idx, slice_range) or not is_within_slice(s_idx, slice_range):\n",
    "            #     # print(\"Label not in slice range:\")\n",
    "            #     idx_shift = None\n",
    "            if not is_within_slice(p_idx, slice_range):\n",
    "                wind[0] = True\n",
    "            if not is_within_slice(s_idx, slice_range):\n",
    "                wind[1] = True\n",
    "        return X, idx_shift, wind\n",
    "    else:\n",
    "        print(\"Unsure?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae2f9bd-e5da-4411-a71c-a5f177636607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNetModel(input_size=(1, 8192, 3), f=7, s=4):\n",
    "    filter_shape = (1, f)\n",
    "    stride_shape = (1, s)\n",
    "\n",
    "    inputs = Input(shape=input_size)\n",
    "\n",
    "    # Encoding block\n",
    "    conv1 = Conv2D(8, filter_shape, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    conv1 = Conv2D(8, filter_shape, activation=\"relu\", padding=\"same\")(conv1)\n",
    "\n",
    "    conv2 = Conv2D(8, filter_shape, activation=\"relu\", strides=stride_shape, padding=\"same\")(conv1)\n",
    "    conv2 = Conv2D(11, filter_shape, activation=\"relu\", padding=\"same\")(conv2)\n",
    "\n",
    "    conv3 = Conv2D(11, filter_shape, activation=\"relu\", strides=stride_shape, padding=\"same\")(conv2)\n",
    "    conv3 = Conv2D(16, filter_shape, activation=\"relu\", padding=\"same\")(conv3)\n",
    "\n",
    "    conv4 = Conv2D(16, filter_shape, activation=\"relu\", strides=stride_shape, padding=\"same\")(conv3)\n",
    "    conv4 = Conv2D(22, filter_shape, activation=\"relu\", padding=\"same\")(conv4)\n",
    "\n",
    "    # Middle (bottleneck)\n",
    "    convm = Conv2D(22, filter_shape, activation=\"relu\", strides=stride_shape, padding=\"same\")(conv4)\n",
    "    convm = Conv2D(32, filter_shape, activation=\"relu\", padding=\"same\")(convm)\n",
    "\n",
    "    # Decoding block\n",
    "    deconv4 = Conv2DTranspose(44, filter_shape, strides=stride_shape, padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4], axis=-1)\n",
    "    uconv4 = Conv2D(22, filter_shape, activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(32, filter_shape, strides=stride_shape, padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3], axis=-1)\n",
    "    uconv3 = Conv2D(16, filter_shape, activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(22, filter_shape, strides=stride_shape, padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2], axis=-1)\n",
    "    uconv2 = Conv2D(11, filter_shape, activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(16, filter_shape, strides=stride_shape, padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1], axis=-1)\n",
    "    uconv1 = Conv2D(8, filter_shape, activation=\"relu\", padding=\"same\")(uconv1)\n",
    "\n",
    "    # Outputs\n",
    "    out1 = Conv2D(1, (1, 1), padding=\"same\")(uconv1)\n",
    "    out2 = Conv2D(1, (1, 1), padding=\"same\")(uconv1)\n",
    "    out3 = Conv2D(1, (1, 1), padding=\"same\")(uconv1)\n",
    "\n",
    "    soft = Softmax(axis=-2)\n",
    "    out1 = soft(out1)\n",
    "    out2 = soft(out2)\n",
    "    out3 = soft(out3)\n",
    "\n",
    "    output = concatenate([out1, out2, out3], axis=-1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26f9f2-85e2-4b47-b8ab-acd8aa642e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultsHistogram(Preds,dataGen):\n",
    "    labels = dataGen.getLabels()\n",
    "    distPList = []\n",
    "    distSList = []\n",
    "    for i in range(dataGen.total_len()):\n",
    "        pLab = labels[i][0]\n",
    "        sLab = labels[i][1]\n",
    "        pPick = np.argmax(Preds[i][0][:,0])\n",
    "        sPick = np.argmax(Preds[i][0][:,1])\n",
    "        distP = pLab - pPick\n",
    "        distS = sLab - sPick\n",
    "        distPList.append(distP)\n",
    "        distSList.append(distS)\n",
    "\n",
    "    bound = 50\n",
    "    fig = plt.figure()\n",
    "\n",
    "    l1 = plt.axvline(x=np.percentile(np.abs(distP), 75), color='blue', linestyle='--', label=r'$P_{75}$: P')\n",
    "    plt.axvline(x=-np.percentile(np.abs(distP), 75), color='blue', linestyle='--')\n",
    "    l2 = plt.axvline(x=np.percentile(np.abs(distS), 75), color='red', linestyle='--', label='$P_{75}$: S')\n",
    "    plt.axvline(x=-np.percentile(np.abs(distS), 75), color='red', linestyle='--')\n",
    "\n",
    "    _,_,l3 = plt.hist(distPList, bins=40, range=(-bound, bound), density=True, color='blue', edgecolor='black', alpha=0.5,\n",
    "             label='P waves')\n",
    "    _,_,l4 = plt.hist(distSList, bins=40, range=(-bound, bound), density=True, color='red', edgecolor='black', alpha=0.5,\n",
    "             label='S waves')\n",
    "\n",
    "    # Custom legend order\n",
    "    handles = [l1, l2, l3[0], l4[0]]\n",
    "    labels = [h.get_label() for h in handles]\n",
    "\n",
    "    plt.xlim([-bound, bound])\n",
    "\n",
    "    plt.xlabel('Residual (samples)')\n",
    "    textblock = (                                                                 \n",
    "                 r\"$P_{75}: P = $\" + str(int(np.percentile(np.abs(distP),75))) + \"\\n\"\n",
    "                 r\"$P_{75}: S = $\" + str(int(np.percentile(np.abs(distS),75))) + \"\\n\"\n",
    "                 )\n",
    "    plt.text(-bound + 2, 0.19, textblock, fontsize=10, color='black', ha='left', va='top')\n",
    "\n",
    "    plt.ylabel('Probability density')\n",
    "    plt.ylim([0, 0.2])\n",
    "    plt.legend(handles, labels)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envIndabaX",
   "language": "python",
   "name": "envindabax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
